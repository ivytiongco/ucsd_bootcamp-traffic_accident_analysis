{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = '../data/raw/'\n",
    "interim_data_dir = '../data/interim/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "url= \"https://crashviewer.nhtsa.dot.gov/CrashAPI\"\n",
    "#/crashes/GetCrashesByLocation?fromCaseYear=2014&toCaseYear=2015&state=1&county=1&format=json\n",
    "\n",
    "fromCaseYear = \"2010\"\n",
    "toCaseYear = \"2020\"\n",
    "state = \"6\"\n",
    "qurl = f\"{url}/crashes/GetCrashesByLocation?fromCaseYear={fromCaseYear}&toCaseYear={toCaseYear}&state={state}&county=73&format=json\"\n",
    "\n",
    "cali = requests.get(qurl).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1895"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cali_df = pd.DataFrame(cali['Results'][0])\n",
    "len(cali_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2015\n",
    "st_case = 60022\n",
    "\n",
    "qurl = f\"{url}/crashes/GetCaseDetails?stateCase={st_case}&caseYear={year}&state=6&format=json\"\n",
    "data = requests.get(qurl).json()\n",
    "case = data['Results'][0][0]['CrashResultSet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ARR_HOUR', 'ARR_HOURNAME', 'ARR_MIN', 'ARR_MINNAME', 'CEvents', 'CF1', 'CF1NAME', 'CF2', 'CF2NAME', 'CF3', 'CF3NAME', 'CITY', 'CITYNAME', 'COUNTY', 'COUNTYNAME', 'CaseYear', 'DAY', 'DAY_WEEK', 'DAY_WEEKNAME', 'DRUNK_DR', 'FATALS', 'FUNC_SYS', 'FUNC_SYSNAME', 'HARM_EV', 'HARM_EVNAME', 'HOSP_HR', 'HOSP_HRNAME', 'HOSP_MN', 'HOSP_MNNAME', 'HOUR', 'HOURNAME', 'LATITUDE', 'LATITUDENAME', 'LGT_COND', 'LGT_CONDNAME', 'LONGITUD', 'LONGITUDNAME', 'MAN_COLL', 'MAN_COLLNAME', 'MILEPT', 'MILEPTNAME', 'MINUTE', 'MINUTENAME', 'MONTH', 'MonthName', 'NHS', 'NHSNAME', 'NOT_HOUR', 'NOT_HOURNAME', 'NOT_MIN', 'NOT_MINNAME', 'NPersons', 'NmCrashes', 'NmImpairs', 'NmPriors', 'PEDS', 'PERMVIT', 'PERNOTMVIT', 'PERSONS', 'PVH_INVL', 'ParkWorks', 'PbTypes', 'RAIL', 'RAILNAME', 'RD_OWNER', 'RD_OWNERNAME', 'RELJCT1', 'RELJCT1NAME', 'RELJCT2', 'RELJCT2NAME', 'REL_ROAD', 'REL_ROADNAME', 'ROAD_FNC', 'ROAD_FNCNAME', 'ROUTE', 'ROUTENAME', 'RUR_URB', 'RUR_URBNAME', 'SCH_BUS', 'SCH_BUSNAME', 'SP_JUR', 'SP_JURNAME', 'STATENAME', 'ST_CASE', 'SafetyEQs', 'State', 'TWAY_ID', 'TWAY_ID2', 'TYP_INT', 'TYP_INTNAME', 'VE_FORMS', 'VE_TOTAL', 'Vehicles', 'WEATHER', 'WEATHER1', 'WEATHER1NAME', 'WEATHER2', 'WEATHER2NAME', 'WEATHERNAME', 'WRK_ZONE', 'WRK_ZONENAME', 'YEAR'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-117.063127780'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case['LONGITUD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_people(v):\n",
    "    for p in v['Persons']:\n",
    "        yield {\n",
    "            'Speed Limit Exceeded': v['SPEEDRELNAME'],\n",
    "            'Speed limit': v['TRAV_SP'],\n",
    "            'Vin Number': v['VINNAME'],\n",
    "            'Traveled Speed Veh': v['VSPD_LIM'],\n",
    "            'Make': v['MAKENAME'],\n",
    "            'Make/Model': v['MAK_MODNAME'],\n",
    "            'Model': v['MODELNAME'],\n",
    "            'Type of Vehicle': v['BODY_TYPNAME'],\n",
    "            \"ZIP Code\": v['DR_ZIP'],\n",
    "            \n",
    "            \"Age\": p['AGE'],\n",
    "            \"Age Name\": p['AGENAME'],\n",
    "            \"County\": p['COUNTYNAME'],\n",
    "            \"Death Day of Month\": p['DEATH_DANAME'],\n",
    "            \"DOA Name\": p['DOANAME'],\n",
    "            # injury sev\n",
    "            \"Injury Severity Name\": p['INJ_SEVNAME'],\n",
    "            \"Race\": p['RACENAME'],\n",
    "            \"Road Type\": p[\"ROAD_FNCNAME\"],\n",
    "            \"Sex\": p[\"SEXNAME\"],\n",
    "            \"Make\": p[\"MAKENAME\"],\n",
    "        }\n",
    "\n",
    "\n",
    "        \n",
    "def get_people(case):\n",
    "\n",
    "    hour = case['HOUR']\n",
    "    minute = case['MINUTE']\n",
    "    time = f\"{hour}:{minute}\"\n",
    "        \n",
    "    accident_info = {\n",
    "        'Lng': case['LONGITUD'],\n",
    "        'Lat': case['LATITUDE'],\n",
    "        'Case Number': case['ST_CASE'],\n",
    "        \"Description of Veh Coll\": case['CF2NAME'], \n",
    "        \"Day of Week\": case['DAY_WEEKNAME'],\n",
    "        \"Drunk Driver\": case['DRUNK_DR'],\n",
    "        \"Year\": case['CaseYear'],\n",
    "        \"Month\": case['MonthName'],\n",
    "        \"Hour\": hour,\n",
    "        \"Time of Accident\": time,\n",
    "    }\n",
    "\n",
    "    vehicles = case['Vehicles']\n",
    "    \n",
    "    people = [{**accident_info, **p} for v in vehicles for p in extract_people(v)]\n",
    "    \n",
    "    return pd.DataFrame(people)\n",
    "\n",
    "def get_events(case):\n",
    "    c_events = [{\n",
    "        'Case Number': case['ST_CASE'],\n",
    "# In a traffic accident AOI is Area of Impact. The spot the two cars collided is measured \n",
    "# to a fixed object, usually the curb, so it can be reconstructed later.\n",
    "        'Area of Impact': e['AOI1NAME'],\n",
    "# standard of evidence\n",
    "# https://safety.fhwa.dot.gov/rsdp/cdip_rpti.aspx\n",
    "        'Standard of Evenidence': e['SOENAME'],\n",
    "        'Event Number': e['EVENTNUM'],\n",
    "        'Vehicle 1': e['VNUMBER1'],\n",
    "        'Vehicle 2': e['VNUMBER2'],\n",
    "    } for e in case['CEvents']]\n",
    "    \n",
    "    return pd.DataFrame(c_events)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from shapely.geometry import shape, Point\n",
    "# depending on your version, use: from shapely.geometry import shape, Point\n",
    "\n",
    "\n",
    "class ZipCoder(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.js = None\n",
    "    \n",
    "    def __get_zip(self, lat, lng):\n",
    "        \n",
    "        point = Point(lng, lat)\n",
    "\n",
    "        for feature in js['features']:\n",
    "            polygon = shape(feature['geometry'])\n",
    "            if polygon.contains(point):\n",
    "                zip_code = feature['properties']['zip']\n",
    "                return zip_code\n",
    "\n",
    "\n",
    "    def __row_to_zip(self, r):\n",
    "        lat = r['Lat']\n",
    "        lng = r['Lng']\n",
    "        return self.__get_zip(lat, lng)\n",
    "\n",
    "    \n",
    "    def ensure_acc_zips(self, df):\n",
    "        with open(f'{ raw_data_dir }Zip Codes.geojson') as f:\n",
    "            self.js = json.load(f)\n",
    "            \n",
    "        acc_zip_col = 'Accident ZIP'\n",
    "\n",
    "        if acc_zip_col not in df.columns: \n",
    "            zip_codes = df.apply(self.__row_to_zip, axis=1)\n",
    "            df[acc_zip_col] = zip_codes\n",
    "            file_path = f\"{ interim_data_dir }people.csv\"\n",
    "            df.to_csv(file_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import grequests\n",
    "from itertools import islice\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def chunk(it, size):\n",
    "    it = iter(it)\n",
    "    return iter(lambda: tuple(islice(it, size)), ())\n",
    "\n",
    "# LARGE CHUNK SIZE WILL BLOW UP SERVER AND CAUSING: AttributeError: 'NoneType' object has no attribute 'json'\n",
    "chunk_size = 5\n",
    "fromCaseYear = \"2010\"\n",
    "toCaseYear = \"2020\"\n",
    "state = \"6\"\n",
    "case_file_base = raw_data_dir\n",
    "\n",
    "data_lists = {}\n",
    "\n",
    "\n",
    "def url_from_row(r):\n",
    "    statecase = r[\"ST_CASE\"]\n",
    "    caseyear = r[\"CaseYear\"]\n",
    "    return f\"{url}/crashes/GetCaseDetails?stateCase={statecase}&caseYear={caseyear}&state=6&format=json\"\n",
    "\n",
    "\n",
    "def get_file_path(case):\n",
    "    return f'{ case_file_base }{ case[\"ST_CASE\"] }.json'\n",
    "    \n",
    "    \n",
    "def load_case(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        case = json.load(f)\n",
    "        return case\n",
    "\n",
    "    \n",
    "def __get_cases():\n",
    "    urls = []\n",
    "    found_locally = 0\n",
    "    for i, r in cali_df.iterrows():\n",
    "        file_path = get_file_path(r)\n",
    "        if os.path.exists(file_path):\n",
    "            found_locally += 1\n",
    "            clear_output(wait=True)\n",
    "            print(f'{ found_locally } files found locally')\n",
    "            yield load_case(file_path)\n",
    "        else:\n",
    "            url = url_from_row(r)\n",
    "            urls.append(url)\n",
    "    print(f'{ len(urls) } need to be fetched. ')\n",
    "    for c in __chunk_and_fetch(urls):\n",
    "        yield c\n",
    "    \n",
    "\n",
    "def __fetch_cases(urls):\n",
    "    rs = (grequests.get(u) for u in urls)\n",
    "    case_data = grequests.map(rs)\n",
    "    return [data.json()['Results'][0][0]['CrashResultSet'] for data in case_data]\n",
    "    \n",
    "    \n",
    "def __save_case(case):\n",
    "    file_path = get_file_path(case)\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(case, json_file)\n",
    "    \n",
    "    \n",
    "def __chunk_and_fetch(urls):\n",
    "    chunked = chunk(urls, chunk_size)\n",
    "    \n",
    "    i = 0\n",
    "    for chunked_urls in chunked:\n",
    "        i += 1\n",
    "        clear_output(wait=True)\n",
    "        print(f'Retrieving chunk { i } of { len(urls) / chunk_size } ...')\n",
    "        cases = __fetch_cases(chunked_urls) \n",
    "        for case in cases:\n",
    "            __save_case(case)\n",
    "            yield case\n",
    "\n",
    "        \n",
    "people_key = 'people'\n",
    "events_key = 'events'\n",
    "\n",
    "\n",
    "def __get_case_lists():\n",
    "    # actualize list to avoid redundant api calls\n",
    "    case_list = list(__get_cases())\n",
    "    \n",
    "    file_path_people = f\"{ interim_data_dir }people.csv\"\n",
    "    people_list = [get_people(case) for case in case_list]\n",
    "    people_df = pd.concat(people_list, ignore_index=True)\n",
    "    people_df.to_csv(file_path_people)\n",
    "    data_lists[people_key] = people_df\n",
    "    \n",
    "    file_path_events = f\"{ interim_data_dir }events.csv\"\n",
    "    event_list = [get_events(case) for case in case_list]\n",
    "    event_df = pd.concat(event_list)\n",
    "    event_df.to_csv(file_path_events)\n",
    "    data_lists[events_key] = event_df\n",
    "\n",
    "    return people_df, event_df\n",
    "    \n",
    "\n",
    "def get_people_list():\n",
    "    cached = get_cached_list(people_key)\n",
    "    if cached is not None:\n",
    "        ZipCoder().ensure_acc_zips(cached)\n",
    "        return cached\n",
    "    df = __get_case_lists()[0]\n",
    "    ZipCoder().ensure_acc_zips(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_event_list():\n",
    "    cached = get_cached_list(events_key)\n",
    "    if cached is not None:\n",
    "        return cached\n",
    "    df = __get_case_lists()[1]\n",
    "    file_path = f\"{ interim_data_dir }events.csv\"\n",
    "    df.to_csv(file_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_cached_list(key):\n",
    "    if key in data_lists:\n",
    "        return data_lists[key]\n",
    "    \n",
    "    file_path = f\"{ interim_data_dir }{ key }.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        data_lists[key] = df\n",
    "        return df\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from census import Census\n",
    "\n",
    "# Census API Key\n",
    "from api_config import census_api_key\n",
    "c = Census(census_api_key, year=2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Population</th>\n",
       "      <th>Poverty Count</th>\n",
       "      <th>Household Income</th>\n",
       "      <th>Per Capita Income</th>\n",
       "      <th>Name</th>\n",
       "      <th>Zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>46.5</td>\n",
       "      <td>724.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>25551.0</td>\n",
       "      <td>ZCTA5 12810</td>\n",
       "      <td>12810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>45.9</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-666666666.0</td>\n",
       "      <td>11590.0</td>\n",
       "      <td>ZCTA5 12811</td>\n",
       "      <td>12811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>64.1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49583.0</td>\n",
       "      <td>23600.0</td>\n",
       "      <td>ZCTA5 12812</td>\n",
       "      <td>12812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46.4</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>58176.0</td>\n",
       "      <td>35508.0</td>\n",
       "      <td>ZCTA5 12814</td>\n",
       "      <td>12814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>54.2</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>60458.0</td>\n",
       "      <td>30685.0</td>\n",
       "      <td>ZCTA5 12815</td>\n",
       "      <td>12815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Median Age  Population  Poverty Count  Household Income  \\\n",
       "0           0        46.5       724.0           78.0           57500.0   \n",
       "1           1        45.9        67.0            0.0      -666666666.0   \n",
       "2           2        64.1        58.0            0.0           49583.0   \n",
       "3           3        46.4      1282.0           51.0           58176.0   \n",
       "4           4        54.2      1103.0          159.0           60458.0   \n",
       "\n",
       "   Per Capita Income         Name  Zipcode  \n",
       "0            25551.0  ZCTA5 12810    12810  \n",
       "1            11590.0  ZCTA5 12811    12811  \n",
       "2            23600.0  ZCTA5 12812    12812  \n",
       "3            35508.0  ZCTA5 12814    12814  \n",
       "4            30685.0  ZCTA5 12815    12815  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Census Search to retrieve data on all zip codes (2013 ACS5 Census)\n",
    "# See: https://github.com/CommerceDataService/census-wrapper for library documentation\n",
    "# See: https://gist.github.com/afhaque/60558290d6efd892351c4b64e5c01e9b for labels\n",
    "import os\n",
    "\n",
    "\n",
    "census_cache = {}\n",
    "\n",
    "def census_by_year(year):\n",
    "    \n",
    "    if year in census_cache:\n",
    "        return census_cache[year]\n",
    "    \n",
    "    file_path = f'{ interim_data_dir }census_{ year }'\n",
    "    if os.path.exists(file_path):\n",
    "        return pd.read_csv(file_path)\n",
    "        \n",
    "    try:\n",
    "        census_data = c.acs5.get((\"NAME\", \"B19013_001E\", \"B01003_001E\", \"B01002_001E\",\n",
    "                              \"B19301_001E\",\n",
    "                              \"B17001_002E\"), {'for': 'zip code tabulation area:*'}, year=year)\n",
    "    # Convert to DataFrame\n",
    "        census_pd = pd.DataFrame(census_data)\n",
    "\n",
    "    # Column Reordering\n",
    "        census_pd = census_pd.rename(columns={\"B01003_001E\": \"Population\",\n",
    "                                              \"B01002_001E\": \"Median Age\",\n",
    "                                              \"B19013_001E\": \"Household Income\",\n",
    "                                              \"B19301_001E\": \"Per Capita Income\",\n",
    "                                              \"B17001_002E\": \"Poverty Count\",\n",
    "                                              \"NAME\": \"Name\",\n",
    "                                              \"zip code tabulation area\": \"Zipcode\"})\n",
    "        census_pd.to_csv(file_path)\n",
    "        return census_pd\n",
    "\n",
    "    except:\n",
    "        print('no data')\n",
    "        return None\n",
    "\n",
    "    \n",
    "# load all census tables 2011 - 2018\n",
    "years = range(2011, 2019)\n",
    "for y in years: census_by_year(y)\n",
    "\n",
    "census_pd = census_by_year(2016)\n",
    "\n",
    "# Visualize\n",
    "print(len(census_pd))\n",
    "census_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 2,
           "op": "addrange",
           "valuelist": "7"
          },
          {
           "key": 2,
           "length": 1,
           "op": "removerange"
          },
          {
           "key": 5,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": 0,
         "op": "patch"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
